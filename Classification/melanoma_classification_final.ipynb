{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "\n",
    "from skimage.io import imsave, imread\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set train and test paths\n",
    "TRAIN_PATH = \"/Users/sangeethags/Desktop/SEM8/AI/Assignment1/assignment2/dataset/others/\"\n",
    "TEST_PATH = \"/Users/sangeethags/Desktop/SEM8/AI/Assignment1/assignment2/dataset/melanoma/\"\n",
    "\n",
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[2]\n",
    "test_ids = next(os.walk(TEST_PATH))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing not infected images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1626/1626 [20:47<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing infected images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 374/374 [04:40<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get and resize train images and masks\n",
    "not_infected_img = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "not_infected_lbl = np.zeros((len(train_ids), 1), dtype=np.bool)\n",
    "print('Getting and resizing not infected images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, img_file in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    img = imread(TRAIN_PATH + img_file)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    not_infected_img[n] = img\n",
    "    not_infected_lbl[n] = 0;\n",
    "    \n",
    "# Get and resize test images and masks\n",
    "infected_img = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "infected_lbl = np.zeros((len(test_ids), 1), dtype=np.bool)\n",
    "#sizes_test = []\n",
    "print('Getting and resizing infected images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, img_file in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    img = imread(TEST_PATH + img_file)[:,:,:IMG_CHANNELS]\n",
    "    #sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    infected_img[n] = img\n",
    "    infected_lbl[n] = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class0len = len(not_infected_img)\n",
    "class1len = len(infected_img)\n",
    "\n",
    "#Append infected and non-infected into one array, shuffle them, then split into train and test\n",
    "all_images = np.zeros((len(train_ids)+len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "all_labels = np.zeros((len(train_ids)+len(test_ids), 1), dtype=np.bool)\n",
    "\n",
    "all_images[0:len(train_ids)] = not_infected_img\n",
    "all_labels[0:len(train_ids)] = not_infected_lbl\n",
    "all_images[len(train_ids):] = infected_img\n",
    "all_labels[len(train_ids):] = infected_lbl\n",
    "\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(all_images,all_labels, test_size=0.25, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 20)      1520      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 20)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               25600500  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 25,628,072\n",
      "Trainable params: 25,628,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "        \n",
    "        # first set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\",input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # second set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    " \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    " \n",
    "        # return the constructed network architecture\n",
    "        return model \n",
    "\n",
    "model = LeNet.build(width=128, height=128, depth=3, classes=2)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1254 - acc: 0.5940 - val_loss: 0.6870 - val_acc: 0.8060\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 1s 968us/step - loss: 1.1232 - acc: 0.5353 - val_loss: 0.6640 - val_acc: 0.8080\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 1.1213 - acc: 0.6193 - val_loss: 0.7033 - val_acc: 0.3660\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 1.1148 - acc: 0.5007 - val_loss: 0.5168 - val_acc: 0.8080\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 1s 828us/step - loss: 1.1091 - acc: 0.5753 - val_loss: 0.7339 - val_acc: 0.2200\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 1.1108 - acc: 0.4687 - val_loss: 0.5439 - val_acc: 0.7940\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 1.0904 - acc: 0.5653 - val_loss: 0.6673 - val_acc: 0.5300\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 1.0835 - acc: 0.5480 - val_loss: 0.6875 - val_acc: 0.4980\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 1.0718 - acc: 0.5427 - val_loss: 0.7000 - val_acc: 0.4480\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 1.0536 - acc: 0.5520 - val_loss: 0.5556 - val_acc: 0.7340\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 1.0559 - acc: 0.5620 - val_loss: 0.6106 - val_acc: 0.6120\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 1.0340 - acc: 0.5973 - val_loss: 0.5981 - val_acc: 0.6360\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 1.0177 - acc: 0.6087 - val_loss: 0.5698 - val_acc: 0.6480\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 1s 802us/step - loss: 1.0131 - acc: 0.6153 - val_loss: 0.6608 - val_acc: 0.5440\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 1s 803us/step - loss: 0.9945 - acc: 0.6140 - val_loss: 0.6929 - val_acc: 0.4980\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.9857 - acc: 0.6060 - val_loss: 0.6076 - val_acc: 0.6040\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 0.9623 - acc: 0.6460 - val_loss: 0.7179 - val_acc: 0.4740\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 1s 805us/step - loss: 0.9433 - acc: 0.6293 - val_loss: 0.6324 - val_acc: 0.6180\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 1s 821us/step - loss: 0.9380 - acc: 0.6647 - val_loss: 0.5360 - val_acc: 0.7300\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.9240 - acc: 0.6747 - val_loss: 0.6767 - val_acc: 0.5620\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.9012 - acc: 0.6673 - val_loss: 0.6420 - val_acc: 0.6080\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.8721 - acc: 0.6980 - val_loss: 0.6698 - val_acc: 0.5860\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 0.8631 - acc: 0.6973 - val_loss: 0.6659 - val_acc: 0.5860\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 1s 800us/step - loss: 0.8265 - acc: 0.7213 - val_loss: 0.6114 - val_acc: 0.7180\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 1s 818us/step - loss: 0.8186 - acc: 0.7173 - val_loss: 0.5836 - val_acc: 0.7040\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 0.7944 - acc: 0.7453 - val_loss: 0.6419 - val_acc: 0.6400\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 0.7601 - acc: 0.7420 - val_loss: 0.8255 - val_acc: 0.4840\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 1s 815us/step - loss: 0.7440 - acc: 0.7473 - val_loss: 0.6003 - val_acc: 0.6980\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 0.7039 - acc: 0.7700 - val_loss: 0.8300 - val_acc: 0.5520\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.6915 - acc: 0.7827 - val_loss: 0.6438 - val_acc: 0.6740\n",
      "F1 = [ 0.77579092  0.4029304 ]\n",
      "Confusion matrix =  [[55, 41], [122, 282]]\n",
      "precision_score =  0.310734463277\n",
      "recall_score =  0.572916666667\n"
     ]
    }
   ],
   "source": [
    "classifier = model.fit(X_train,Y_train, batch_size = 10, epochs = 30, verbose = True, validation_data = (X_test, Y_test), class_weight = {0:1, 1:class0len/class1len})\n",
    "Y_pred = model.predict(X_test,verbose=\"True\")\n",
    "Y_classes = Y_pred.argmax(axis=-1)\n",
    "Y_pred = Y_pred.round()\n",
    "\n",
    "print('F1 =', f1_score(testY, Y_pred, average=None))\n",
    "testY = testY.argmax(1)\n",
    "Y_pred = Y_pred.argmax(1)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(testY, Y_pred, labels=None, sample_weight=None).ravel()\n",
    "cm = [[tp, fn], [fp, tn]]\n",
    "print('Confusion matrix = ', cm)\n",
    "print('precision_score = ', precision_score(testY, Y_pred, pos_label=1, average='binary'))\n",
    "print('recall_score = ', recall_score(testY, Y_pred, pos_label=1, average='binary'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Assignment1",
   "language": "python",
   "name": "assignment1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
